{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Classification de données textuelles </H1>\n",
    "\n",
    "\n",
    "Lors de l'étape d'ingénierie de données textuelles nous avons vu que diverses opérations pouvaient être appliquées sur les textes et qu'au final il est possible d'obtenir des textes simplifiés. Nous allons, à présent, étudier comment faire de la classification à partir de données textuelles et comment convertir les textes en vecteurs pour pouvoir faire de la classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'un document a été transformé en une séquence de mot, il est nécessaire de la transformer en vecteur. C'est le rôle de la vectorisation.  \n",
    "\n",
    "\n",
    "\n",
    "** Bag of Words **\n",
    "\n",
    "La manière la plus simple de vectorisation est d'utiliser les Bag of Words (BOW). Il s'agit, à partir d'une liste de mots (vocabulaire) de compter le nombre d'apparition du mot du vocabulaire dans le document.  \n",
    "\n",
    "Cette opération se fait par :\n",
    "1. Création d'une instance de la classe CountVectorizer\n",
    "1. Appel de la fonction fit() pour apprendre le vocabulaire à partir de document\n",
    "1. Appel de la fonction transform() sur un ou plusieurs documents afin de les encoder dans le vecteur.  \n",
    "\n",
    "Attention, par défaut, CountVectorizer effectue un certain nombre de pré-traitements comme par exemple mise en minuscule. Voir https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 7, 'is': 5, 'an': 0, 'example': 3, 'of': 6, 'countvectorizer': 1, 'for': 4, 'creating': 2, 'vector': 8}\n",
      "Taille du vecteur :\n",
      " (1, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texte = [\"This is an example of CountVectorizer for creating a vector\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# creation du vocabulaire\n",
    "vectorizer.fit(texte)\n",
    "# Contenu du vocabulaire\n",
    "print(vectorizer.vocabulary_)\n",
    "# encodage du document\n",
    "vector = vectorizer.transform(texte)\n",
    "\n",
    "print (\"Taille du vecteur :\\n\",vector.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est donc à présent possible de traiter un ensemble de documents comme le montre l'exemple suivant. Nous créons également un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>40</th>\n",
       "      <th>anything</th>\n",
       "      <th>be</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>my</th>\n",
       "      <th>one</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   40  anything  be  document  else  first  is  last  may  maybe  my  one  \\\n",
       "0   0         0   0         1     0      1   1     0    0      0   1    0   \n",
       "1   0         0   0         1     0      0   1     0    0      0   0    0   \n",
       "2   0         0   0         1     0      0   1     0    0      1   0    0   \n",
       "3   1         1   1         0     1      0   0     0    1      0   0    0   \n",
       "4   0         0   0         0     0      0   1     1    0      0   0    1   \n",
       "\n",
       "   the  third  this  yes  \n",
       "0    0      0     1    0  \n",
       "1    1      0     1    0  \n",
       "2    1      1     1    0  \n",
       "3    0      0     0    0  \n",
       "4    1      0     1    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is my first document.',\n",
    "    'This is the document 2 !',\n",
    "    'Maybe this is the third document?',\n",
    "    'Anything else? may be 40',\n",
    "    'Yes !! this is the last one'\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# vectorizer.get_feature_names())\n",
    "# contient le vocabulaire\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prise en compte des prétraitements  **  \n",
    "\n",
    "Considérons les prétraitements suivants qui permettent de supprimer les caractères non Ascii, de mettre en minuscule, d'enlever les ponctuations, de remplacer les nombres et d'enlever les stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import re\n",
    "import inflect\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word) \n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens=normalize(tokens)\n",
    "    text=\"\".join([\" \"+i for i in tokens]).strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte avant le nettoyage \n",
      "\n",
      "we have to think that is text is 1000 *#better than. the \n",
      "Texte après le nettoyage \n",
      "\n",
      "think text one thousand better\n"
     ]
    }
   ],
   "source": [
    "texte=\"we have to think that is text is 1000 *#better than. the \"\n",
    "print (\"Texte avant le nettoyage \\n\")\n",
    "print (texte)\n",
    "texte=clean_text(texte)\n",
    "print (\"Texte après le nettoyage \\n\")\n",
    "print (texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'appel aux fonctions de prétraitements peut se faire directement dans CountVectorizer. Attention cependant il est préférable de ne pas le faire. Par exemple dans le cas d'un pipeline et d'un gridsearch le prétraitement sera effectué à chaque fois ! Il est par contre utile de le faire lors de la dernière étape et que le modèle est sauvegardé pour permettre qu'un nouveau document puisse être transformé avant d'être mis sous la forme d'un vecteur (voir plus bas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print (len(corpus))\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i]=clean_text(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anything</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>forty</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>two</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anything  document  else  first  forty  last  may  maybe  one  third  two  \\\n",
       "0         0         1     0      1      0     0    0      0    0      0    0   \n",
       "1         0         1     0      0      0     0    0      0    0      0    1   \n",
       "2         0         1     0      0      0     0    0      1    0      1    0   \n",
       "3         1         0     1      0      1     0    1      0    0      0    0   \n",
       "4         0         0     0      0      0     1    0      0    1      0    0   \n",
       "\n",
       "   yes  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#ici le preprocessor ne sert à rien\n",
    "# car les données ont été nettoyées avant.\n",
    "vectorizer = CountVectorizer(\n",
    "    preprocessor=clean_text\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel dans CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anything</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>forty</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>two</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anything  document  else  first  forty  last  may  maybe  one  third  two  \\\n",
       "0         0         1     0      1      0     0    0      0    0      0    0   \n",
       "1         0         1     0      0      0     0    0      0    0      0    1   \n",
       "2         0         1     0      0      0     0    0      1    0      1    0   \n",
       "3         1         0     1      0      1     0    1      0    0      0    0   \n",
       "4         0         0     0      0      0     1    0      0    1      0    0   \n",
       "\n",
       "   yes  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    'This is my first document.',\n",
    "    'This is the document 2 !',\n",
    "    'Maybe this is the third document?',\n",
    "    'Anything else? may be 40',\n",
    "    'Yes !! this is the last one'\n",
    "]\n",
    "#Rappel ce n'est pas efficace\n",
    "#il vaut mieux traiter les données avant\n",
    "#attention aux pipelines\n",
    "vectorizer = CountVectorizer(\n",
    "    preprocessor=clean_text\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TfidfVectorizer **\n",
    "\n",
    "CountVectorizer en prenant en compte l'occurrence des mots est souvent trop limité. Une alternative est d'utiliser la \n",
    "mesure TF-IDF (Term Frequency – Inverse Document) via une instance de la classe TfidfVectorizer. Le principe est le même que pour CountVectorizer.\n",
    "\n",
    "Remarque : Il est possible si CountVectorizer a déjà été utilisé de le faire suivre par TfidfTransformer pour simplement mettre à jour les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>40</th>\n",
       "      <th>anything</th>\n",
       "      <th>be</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>my</th>\n",
       "      <th>one</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569497</td>\n",
       "      <td>0.320844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320844</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455196</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356359</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.299781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278803</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>0.331422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278803</td>\n",
       "      <td>0.494873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         40  anything        be  document      else     first        is  \\\n",
       "0  0.000000  0.000000  0.000000  0.381399  0.000000  0.569497  0.320844   \n",
       "1  0.000000  0.000000  0.000000  0.541107  0.000000  0.000000  0.455196   \n",
       "2  0.000000  0.000000  0.000000  0.356359  0.000000  0.000000  0.299781   \n",
       "3  0.447214  0.447214  0.447214  0.000000  0.447214  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.278803   \n",
       "\n",
       "       last       may     maybe        my       one       the     third  \\\n",
       "0  0.000000  0.000000  0.000000  0.569497  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.541107  0.000000   \n",
       "2  0.000000  0.000000  0.532109  0.000000  0.000000  0.356359  0.532109   \n",
       "3  0.000000  0.447214  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.494873  0.000000  0.000000  0.000000  0.494873  0.331422  0.000000   \n",
       "\n",
       "       this       yes  \n",
       "0  0.320844  0.000000  \n",
       "1  0.455196  0.000000  \n",
       "2  0.299781  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.278803  0.494873  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is my first document.',\n",
    "    'This is the document 2 !',\n",
    "    'Maybe this is the third document?',\n",
    "    'Anything else? may be 40',\n",
    "    'Yes !! this is the last one'\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# vectorizer.get_feature_names())\n",
    "# contient le vocabulaire\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anything</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>forty</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>two</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anything  document  else     first  forty     last  may    maybe      one  \\\n",
       "0       0.0  0.556451   0.0  0.830881    0.0  0.00000  0.0  0.00000  0.00000   \n",
       "1       0.0  0.556451   0.0  0.000000    0.0  0.00000  0.0  0.00000  0.00000   \n",
       "2       0.0  0.427993   0.0  0.000000    0.0  0.00000  0.0  0.63907  0.00000   \n",
       "3       0.5  0.000000   0.5  0.000000    0.5  0.00000  0.5  0.00000  0.00000   \n",
       "4       0.0  0.000000   0.0  0.000000    0.0  0.57735  0.0  0.00000  0.57735   \n",
       "\n",
       "     third       two      yes  \n",
       "0  0.00000  0.000000  0.00000  \n",
       "1  0.00000  0.830881  0.00000  \n",
       "2  0.63907  0.000000  0.00000  \n",
       "3  0.00000  0.000000  0.00000  \n",
       "4  0.00000  0.000000  0.57735  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appel d'un pré-prétraiment\n",
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=clean_text\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel de fonction de prétraitement dans TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anything</th>\n",
       "      <th>document</th>\n",
       "      <th>else</th>\n",
       "      <th>first</th>\n",
       "      <th>forty</th>\n",
       "      <th>last</th>\n",
       "      <th>may</th>\n",
       "      <th>maybe</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>two</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anything  document  else     first  forty     last  may    maybe      one  \\\n",
       "0       0.0  0.556451   0.0  0.830881    0.0  0.00000  0.0  0.00000  0.00000   \n",
       "1       0.0  0.556451   0.0  0.000000    0.0  0.00000  0.0  0.00000  0.00000   \n",
       "2       0.0  0.427993   0.0  0.000000    0.0  0.00000  0.0  0.63907  0.00000   \n",
       "3       0.5  0.000000   0.5  0.000000    0.5  0.00000  0.5  0.00000  0.00000   \n",
       "4       0.0  0.000000   0.0  0.000000    0.0  0.57735  0.0  0.00000  0.57735   \n",
       "\n",
       "     third       two      yes  \n",
       "0  0.00000  0.000000  0.00000  \n",
       "1  0.00000  0.830881  0.00000  \n",
       "2  0.63907  0.000000  0.00000  \n",
       "3  0.00000  0.000000  0.00000  \n",
       "4  0.00000  0.000000  0.57735  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appel d'un pré-prétraiment\n",
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=clean_text\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Les ngrams **\n",
    "\n",
    "Très souvent il est utile de prendre en compte les n-grammes, i.e. la suite de n mots consécutifs car ils peuvent être important pour la classification. Il est tout à fait possible de les obtenir soit pendant l'étape de prétraitement, soit lors de l'étape de vectorisation en le passant en paramètre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anything</th>\n",
       "      <th>anything else</th>\n",
       "      <th>document</th>\n",
       "      <th>document two</th>\n",
       "      <th>else</th>\n",
       "      <th>else may</th>\n",
       "      <th>first</th>\n",
       "      <th>first document</th>\n",
       "      <th>forty</th>\n",
       "      <th>last</th>\n",
       "      <th>...</th>\n",
       "      <th>may</th>\n",
       "      <th>may forty</th>\n",
       "      <th>maybe</th>\n",
       "      <th>maybe third</th>\n",
       "      <th>one</th>\n",
       "      <th>third</th>\n",
       "      <th>third document</th>\n",
       "      <th>two</th>\n",
       "      <th>yes</th>\n",
       "      <th>yes last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427993</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427993</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317527</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474125</td>\n",
       "      <td>0.474125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474125</td>\n",
       "      <td>0.474125</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anything  anything else  document  document two      else  else may  \\\n",
       "0  0.000000       0.000000  0.427993       0.00000  0.000000  0.000000   \n",
       "1  0.000000       0.000000  0.427993       0.63907  0.000000  0.000000   \n",
       "2  0.000000       0.000000  0.317527       0.00000  0.000000  0.000000   \n",
       "3  0.377964       0.377964  0.000000       0.00000  0.377964  0.377964   \n",
       "4  0.000000       0.000000  0.000000       0.00000  0.000000  0.000000   \n",
       "\n",
       "     first  first document     forty      last    ...          may  may forty  \\\n",
       "0  0.63907         0.63907  0.000000  0.000000    ...     0.000000   0.000000   \n",
       "1  0.00000         0.00000  0.000000  0.000000    ...     0.000000   0.000000   \n",
       "2  0.00000         0.00000  0.000000  0.000000    ...     0.000000   0.000000   \n",
       "3  0.00000         0.00000  0.377964  0.000000    ...     0.377964   0.377964   \n",
       "4  0.00000         0.00000  0.000000  0.447214    ...     0.000000   0.000000   \n",
       "\n",
       "      maybe  maybe third       one     third  third document      two  \\\n",
       "0  0.000000     0.000000  0.000000  0.000000        0.000000  0.00000   \n",
       "1  0.000000     0.000000  0.000000  0.000000        0.000000  0.63907   \n",
       "2  0.474125     0.474125  0.000000  0.474125        0.474125  0.00000   \n",
       "3  0.000000     0.000000  0.000000  0.000000        0.000000  0.00000   \n",
       "4  0.000000     0.000000  0.447214  0.000000        0.000000  0.00000   \n",
       "\n",
       "        yes  yes last  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.447214  0.447214  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appel d'un pré-prétraiment\n",
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=clean_text,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=vectorizer.transform(corpus).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir du moment où nous disposons d'une matrice, nous pouvons appliquer toutes les approches que nous avons vu précédement.  \n",
    "Nous illustrons au travers d'un exemple de classification multiclasse. Ce dernier est tiré de \"The 20 newsgroups text dataset\". Il s'agit d'un jeu de données de 20 newsgroups comprenant à peu près 18000 news sur 20 sujets différents. \n",
    "\n",
    "Ce jeu de données est disponible sous scikit learn qui propose des fonctions pour le manipuler : https://scikit-learn.org/stable/datasets/index.html#newsgroups-dataset  \n",
    "\n",
    "fetch_20newsgroups permet de charger le fichier. Il est possible de récupérer un jeu d'entrainement, de test ou l'ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Présentation du jeu de données **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liste des topics \n",
      "\n",
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "from pprint import pprint\n",
    "print (\"liste des topics \\n\")\n",
    "pprint(list(news.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Téléchargement d'une partie des topics **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu de données\n",
      "\n",
      "(4386,)\n",
      "Un exemple de données\n",
      "\n",
      "From: LMARSHA@cms.cc.wayne.edu (Laurie Marshall)\n",
      "Subject: Re: WHERE ARE THE DOUBTERS NOW?  HMM?\n",
      "Article-I.D.: cms.16BA79DBA.LMARSHA\n",
      "Organization: Wayne State University, Detroit MI  U.S.A.\n",
      "Lines: 22\n",
      "NNTP-Posting-Host: cms.cc.wayne.edu\n",
      "\n",
      "In article <1993Apr4.051942.27095@ramsey.cs.laurentian.ca>\n",
      "maynard@ramsey.cs.laurentian.ca (Roger Maynard) writes:\n",
      " \n",
      ">\n",
      ">For those of you who can only decide which team is best after you have\n",
      ">seen the standings:\n",
      ">\n",
      ">TOR  42 25 11  95   .609\n",
      ">CHI  42 25 11  95   .609\n",
      ">DET  44 28  9  97   .599\n",
      ">VAN  41 28  9  91   .583\n",
      ">\n",
      ">No team in the Campbell Conference has a better record than Toronto.\n",
      " \n",
      "  That's true, but according to your stats, Chicago has just as good a\n",
      "record as Toronto.  It's interesting that you should list Toronto ahead\n",
      "of Chicago.\n",
      " \n",
      " Laurie Marshall\n",
      " Wayne State University\n",
      " Detroit, Michigan\n",
      " Go Wings!!\n",
      " \n",
      " TOPIC :  2 \n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'rec.sport.hockey','comp.graphics', 'sci.space']\n",
    "\n",
    "news = fetch_20newsgroups(subset='all',\n",
    "                          categories=categories)\n",
    "\n",
    "print (\"Taille du jeu de données\\n\")\n",
    "print (news.filenames.shape)\n",
    "\n",
    "print (\"Un exemple de données\\n\")\n",
    "print (news.data[5], '\\n TOPIC : ',news.target[5],\n",
    "       '\\n*******************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nettoyage des données **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_news (data):\n",
    "    for i in range(len(data)):\n",
    "        #print (i)\n",
    "        data[i]=clean_text(data[i])\n",
    "    return data    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.data=clean_news(news.data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Vectorisation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(news.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** X et y **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specification des variables à prédire et de la classe X et y\n",
    "X = vectors.toarray()\n",
    "\n",
    "y = news.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Création du jeu d'apprentissage et de test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utilisation du classifieur **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 166.380s\n",
      "Les différentes accuracy pour les 10 évaluations sont : \n",
      " [0.94305239 0.9498861  0.94305239 0.94077449 0.93394077 0.93621868\n",
      " 0.93835616 0.94292237 0.91552511 0.95205479] \n",
      "\n",
      "Accuracy moyenne :  0.939578327664576  standard deviation 0.009600959296048284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "seed=7\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "clf = GaussianNB()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "t0 = time()\n",
    "score = cross_val_score(clf, X, y, cv=k_fold, scoring=scoring)\n",
    "print(\"Réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('Les différentes accuracy pour les 10 évaluations sont : \\n',\n",
    "      score,'\\n')\n",
    "print ('Accuracy moyenne : ',score.mean(), \n",
    "       ' standard deviation', score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mise en place d'un pipeline **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pascalponcelet/Desktop/Sicki-learn/Tools/tools/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit réalisé en 0.532s\n",
      "Prédiction réalisée en 0.603s\n",
      "\n",
      " accuracy: 0.9397590361445783 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[510   6   1   5  24]\n",
      " [  1 665   4   4   1]\n",
      " [  0   9 722   0   1]\n",
      " [  1  21   4 653   1]\n",
      " [ 82   9   3   8 336]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       546\n",
      "           1       0.94      0.99      0.96       675\n",
      "           2       0.98      0.99      0.98       732\n",
      "           3       0.97      0.96      0.97       680\n",
      "           4       0.93      0.77      0.84       438\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      3071\n",
      "   macro avg       0.94      0.93      0.93      3071\n",
      "weighted avg       0.94      0.94      0.94      3071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', \n",
    "                                      penalty='l2',\n",
    "                                      alpha=1e-3, \n",
    "                                      random_state=42, \n",
    "                                      max_iter=5, tol=None)),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=news.data\n",
    "y=news.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\n',classification_report(y_test, result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mise en place d'un gridsearch avec pipeline pour rechercher le meilleur classifieur **\n",
    "\n",
    "Dans cette section nous intégrons un pipeline complet : lancement du TfidfVectorizer , utilisation de deux classifieurs (DecisionTreeClassifier et SGDClassifier) avec les hyperparamètres  pour évaluer le meilleur via GridSearchCV. Attention le processus de gridsearch est très long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: Linear classifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pascalponcelet/Desktop/Sicki-learn/Tools/tools/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit réalisé en 8.424s\n",
      "Meilleurs paramètres : {'clf__alpha': 1e-06, 'clf__max_iter': 5, 'clf__penalty': 'l2'}\n",
      "Meilleur score d'accuracy sur l'entrainement: 0.913\n",
      "Prédiction réalisée en 0.682s\n",
      "Score d'accuracy pour les meilleurs paramètres sur jeu de test : 0.933\n",
      "\n",
      " matrice de confusion \n",
      " [[495   5   0   5  41]\n",
      " [  3 653  13   4   2]\n",
      " [  1  10 716   3   2]\n",
      " [  7  17   8 643   5]\n",
      " [ 58   8   8   7 357]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       546\n",
      "           1       0.94      0.97      0.95       675\n",
      "           2       0.96      0.98      0.97       732\n",
      "           3       0.97      0.95      0.96       680\n",
      "           4       0.88      0.82      0.84       438\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3071\n",
      "   macro avg       0.93      0.92      0.92      3071\n",
      "weighted avg       0.93      0.93      0.93      3071\n",
      "\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Fit réalisé en 108.210s\n",
      "Meilleurs paramètres : {'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 10}\n",
      "Meilleur score d'accuracy sur l'entrainement: 0.634\n",
      "Prédiction réalisée en 0.712s\n",
      "Score d'accuracy pour les meilleurs paramètres sur jeu de test : 0.631\n",
      "\n",
      " matrice de confusion \n",
      " [[293  44  16 141  52]\n",
      " [  3 518  14 140   0]\n",
      " [  3 108 473 148   0]\n",
      " [  1 121   7 550   1]\n",
      " [142  52  13 128 103]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59       546\n",
      "           1       0.61      0.77      0.68       675\n",
      "           2       0.90      0.65      0.75       732\n",
      "           3       0.50      0.81      0.62       680\n",
      "           4       0.66      0.24      0.35       438\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      3071\n",
      "   macro avg       0.67      0.60      0.60      3071\n",
      "weighted avg       0.67      0.63      0.62      3071\n",
      "\n",
      "\n",
      "Classifier avec la meilleur accuracy sur le jeu de test\n",
      " Linear classifiers\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Specification des pipelines\n",
    "# programmation à optimiser par une fonction :)\n",
    "pipeline_SGDC = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                    ('clf', SGDClassifier())])\n",
    "\n",
    "\n",
    "parameters_SGDC = [\n",
    "    {'clf__max_iter': (5,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet')}\n",
    "]\n",
    "\n",
    "pipeline_DT = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                   ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "#param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 5, 8, 10]\n",
    "parameters_DT = [\n",
    "    {'clf__min_samples_leaf': param_range,\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=news.data\n",
    "y=news.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "# Creation des GridSearchCV avec les pipelines spécifiques\n",
    "\n",
    "gs_SGDC = GridSearchCV(pipeline_SGDC, \n",
    "                       parameters_SGDC, \n",
    "                       cv=3,\n",
    "                       n_jobs=-1, \n",
    "                       scoring='accuracy')\n",
    "\n",
    "\n",
    "gs_DT = GridSearchCV(pipeline_DT, \n",
    "                     parameters_DT, \n",
    "                     cv=3,\n",
    "                     n_jobs=-1, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "grids = [gs_SGDC, gs_DT]\n",
    "grid_dict={0:'Linear classifiers', 1:'Decision Tree'}\n",
    "\n",
    "best_acc = 0.0\n",
    "best_clf = 0.0\n",
    "best_gs = ''\n",
    "\n",
    "for idx,gs in enumerate(grids):\n",
    "    print('\\nClassifier: %s' % grid_dict[idx])\n",
    "    t0 = time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print('Meilleurs paramètres : %s' % gs.best_params_)\n",
    "\n",
    "    print(\"Meilleur score d'accuracy sur l'entrainement: %.3f\" % gs.best_score_)\n",
    "    # Prediction sur le jeu de test avec les meilleurs paramètres\n",
    "    t0 = time()\n",
    "    result = gs.predict(X_test)\n",
    "    print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    print(\"Score d'accuracy pour les meilleurs paramètres sur jeu de test : %.3f\"  % accuracy_score(y_test, result))\n",
    "\n",
    "    print ('\\n matrice de confusion \\n',confusion_matrix(y_test, result))\n",
    "\n",
    "    print ('\\n',classification_report(y_test, result))\n",
    "    \n",
    "    #Modele avec la meilleure accuracy sur le jeu de test\n",
    "    if accuracy_score(y_test, result) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, result)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "        \n",
    "        \n",
    "        \n",
    "print('\\nClassifier avec la meilleur accuracy sur le jeu de test\\n',\n",
    "      grid_dict[best_clf])        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recupération du meilleur classifieur avec ses paramètres **\n",
    "\n",
    "Une fois le résultat obtenu, il est possible de récupérer le meilleur classifieur et ses paramètres. Ici il s'agit de Linear Classifier (SGDClassifier). Dans la suite nous montrons comment relancer une classification via un pipeline et une sauvegarde. Attention ici dans le pipeline nous ajoutons le clean_text (cf remarques précédentes) et nous sauvegardons le modèle pour pouvoir l'utiliser après avec d'autres données.   \n",
    "\n",
    "Le fait de mettre le clean_text dans le pipeline permet lors de la sauvegarde de celui-ci de pouvoir lorsqu'il y a de nouvelles données de les relancer dans le pipeline (les donnés récupéreront dont la matrice du TfidfVectorizer et les pré-traitements associés). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement du fit \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pascalponcelet/Desktop/Sicki-learn/Tools/tools/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit réalisé en 92.018s\n",
      "Lancement de la prédiction \n",
      "\n",
      "Prédiction réalisée en 211.909s\n",
      "\n",
      " accuracy: 0.9296646043633996 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[495   5   7   8  31]\n",
      " [  4 647  12   9   3]\n",
      " [  0   7 723   1   1]\n",
      " [  5  20  13 637   5]\n",
      " [ 64   8   9   4 353]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       546\n",
      "           1       0.94      0.96      0.95       675\n",
      "           2       0.95      0.99      0.97       732\n",
      "           3       0.97      0.94      0.95       680\n",
      "           4       0.90      0.81      0.85       438\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3071\n",
      "   macro avg       0.92      0.92      0.92      3071\n",
      "weighted avg       0.93      0.93      0.93      3071\n",
      "\n",
      "\n",
      "Sauvegarde du pipeline grid search\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Recupération des données pour l'exemple\n",
    "#et partir proprement\n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'rec.sport.hockey','comp.graphics', 'sci.space']\n",
    "\n",
    "news = fetch_20newsgroups(subset='all',\n",
    "                          categories=categories)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(preprocessor=clean_text)),\n",
    "                ('clf', SGDClassifier(loss='hinge', \n",
    "                                      penalty='l2',\n",
    "                                      alpha=1e-05, \n",
    "                                      random_state=42, \n",
    "                                      max_iter=5, \n",
    "                                      tol=None)),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=news.data\n",
    "y=news.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "print (\"Lancement du fit \\n\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "print (\"Lancement de la prédiction \\n\")\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "\n",
    "\n",
    "print ('\\n',classification_report(y_test, result))\n",
    "\n",
    "print(\"\\nSauvegarde du pipeline grid search\") \n",
    "filename = 'thebestone.pkl'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utilisation de nouvelles données **  \n",
    "\n",
    "L'objectif ici est d'utiliser de nouvelles données à partir du modèle appris. Lors de la sauvegarde le pipeline entier a été sauvegardé. Cela implique que lorsque l'on va vouloir prédire les prétraitements du pipeline vont être appliqués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle \n",
      "\n",
      "A partir d'un nouveau texte\n",
      "\n",
      "Pour l'exemple utilisation d'un texte de 20newsgroup\n",
      "\n",
      "Sélection aléatoire de 20 documents \n",
      "\n",
      "Prédiction des news séléctionnées\n",
      "\n",
      "Valeurs réelles vs. valeurs prédites\n",
      "\n",
      "News :  906 \t réelle  2  prédite  2\n",
      "News :  3141 \t réelle  3  prédite  3\n",
      "News :  2906 \t réelle  4  prédite  0\n",
      "News :  693 \t réelle  2  prédite  2\n",
      "News :  3454 \t réelle  1  prédite  1\n",
      "News :  2993 \t réelle  3  prédite  3\n",
      "News :  4080 \t réelle  3  prédite  3\n",
      "News :  4042 \t réelle  1  prédite  1\n",
      "News :  1520 \t réelle  2  prédite  2\n",
      "News :  2277 \t réelle  2  prédite  2\n",
      "News :  1769 \t réelle  3  prédite  3\n",
      "News :  3359 \t réelle  2  prédite  2\n",
      "News :  2642 \t réelle  1  prédite  1\n",
      "News :  4247 \t réelle  1  prédite  1\n",
      "News :  1871 \t réelle  0  prédite  0\n",
      "News :  3921 \t réelle  1  prédite  1\n",
      "News :  976 \t réelle  3  prédite  3\n",
      "News :  1132 \t réelle  3  prédite  3\n",
      "News :  2475 \t réelle  2  prédite  2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (\"Chargement du modèle \\n\")\n",
    "filename = 'thebestone.pkl'\n",
    "clf_loaded = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "print (\"A partir d'un nouveau texte\\n\")\n",
    "print (\"Utilisation d'un texte de 20newsgroup\\n\")\n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'rec.sport.hockey','comp.graphics', 'sci.space']\n",
    "\n",
    "news = fetch_20newsgroups(subset='all',\n",
    "                          categories=categories)\n",
    "\n",
    "print (\"Sélection aléatoire de 20 documents \\n\")\n",
    "from random import randint\n",
    "samples=[]\n",
    "samples_result=[]\n",
    "sample_new=[]\n",
    "for i in range(1,20):\n",
    "    val=randint(1,4385)\n",
    "    sample_new.append(val)\n",
    "    samples.append(news.data[val])\n",
    "    samples_result.append(news.target[val])\n",
    "    \n",
    "print (\"Prédiction des news séléctionnées\\n\")    \n",
    "    \n",
    " \n",
    "\n",
    "result = clf_loaded.predict(samples)\n",
    "\n",
    "print (\"Valeurs réelles vs. valeurs prédites\\n\") \n",
    "for i in range(len(result)):\n",
    "    print (\"News : \",sample_new[i], \n",
    "           \"\\t réelle \", \n",
    "           samples_result[i], \n",
    "           \" prédite \",\n",
    "           result [i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
