{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Premières classifications </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de faire des premières classifications. Pour cela nous utilisons le jeu de données IRIS qui est très connu dans la communauté.  \n",
    "\n",
    "Dans un premier temps, nous présentons une première classification pour apprendre à utiliser un classifieur et à prédire une valeur. Les jeux de données d'apprentissage et de de test sont présentés par la suite. Nous présentons ensuite différentes mesures pour évaluer un modèle.   \n",
    "Etant donné qu'il n'est pas possible d'avoir un classifieur universel (NO FREE LUNCH THEOREM), nous verrons comment utiliser différents classifieurs et comment rechercher les meilleurs paramètres d'un classifieur. Enfin nous verrons comment sauvegarder et ré-utiliser un modèle appris.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sickit learn met régulièrement à jour des versions et \n",
    "#indique des futurs warnings. \n",
    "#ces deux lignes permettent de ne pas les afficher.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Le jeu de données IRIS </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous considérons par la suite le jeu de données des IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', \n",
    "         'Species']\n",
    "\n",
    "df = pd.read_csv(url, names=names)\n",
    "# 5 premières lignes du fichier\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toute première classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classification supervisée considère les données sous la forme ($X$,$Y$) où $X$ correspond aux variables prédictives et $Y$ le résultat d'une observation, i.e. la variable à prédire. \n",
    "En se basant sur un jeu d'apprentissage, un algorithme de classification supervisée cherche une fonction mathématique $F$ qui permet de transformer (au mieux) $X$ vers $Y$, i.e. $F(X) \\approx Y$.  \n",
    "\n",
    "Convention : les variables prédictives sont celles associées aux objets, généralement stockées sous la forme d'une matrice aussi, par convention, elles sont souvent notées en majuscule (notation d'une matrice). Les variables à prédire sont généralement stockées dans un vecteur et sont souvent notées avec une lettre majuscle (notation d'un vecteur).  \n",
    "\n",
    "Autrement il est tout à fait possible d'utiliser des noms de variables significatives comme data, target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values #necessité de convertir le dataframe en numpy\n",
    "#X matrice - utilisation du X majuscule\n",
    "X = array[:,0:4] \n",
    "#y vecteur - utilisation du y minuscule\n",
    "y = array[:,4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans scikit-learn, pour apprendre un modèle, un estimateur est créé en appelant sa méthode *fit(X, y)*.  \n",
    "Dans l'exemple qui suit nous utilisons un classifieur naïve Bayes (https://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X, y) \n",
    "# la ligne affichée dans le Out indique les hyperparamètres \n",
    "#du classifieur s'ils existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ligne affichée dans le Out indique les hyperparamètres du classifieur s'ils existent. \n",
    "Il est également possible de les obtenir à l'aide de :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'priors': None, 'var_smoothing': 1e-09}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est alors possible de prédire une valeur non lue à l'aide de la méthode *predict*. Par exemple, nous savons que les valeurs du 5ième IRIS sont 5.0,\t3.6,\t1.4,\t0.2 et qu'il appartient à la classe Iris-setosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La prédiction du modèle pour [ 5.0,  3.6,  1.4,  0.2] est ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "#Prediction du résultat\n",
    "result = clf.predict([[ 5.0,  3.6,  1.4,  0.2]])\n",
    "print ('La prédiction du modèle pour [ 5.0,  3.6,  1.4,  0.2] est', \n",
    "       result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de la prédiction sur les données d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(X)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une première évaluation de la qualité de la prédiction peut se faire avec le calcul de l'*accuracy* (pourcentage de prédictions correctes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print ('accuracy: ',accuracy_score(result, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le constater, même sur le jeu d'apprentissage il y a des erreurs dans le modèle appris.\n",
    "Pour connaître les objets mal classés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les objets mal classés sont :\n",
      "\n",
      " 52     Iris-versicolor\n",
      "70     Iris-versicolor\n",
      "77     Iris-versicolor\n",
      "106     Iris-virginica\n",
      "119     Iris-virginica\n",
      "133     Iris-virginica\n",
      "Name: Species, dtype: object\n",
      "\n",
      "\n",
      "\n",
      " [ 52  70  77 106 119 133] classé en  ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor'] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(y)\n",
    "#misclassified = np.where(y_test != clf.predict(X_test))\n",
    "misclassified = np.where(y != clf.predict(X))\n",
    "\n",
    "\n",
    "print('Les objets mal classés sont :')\n",
    "\n",
    "i=0\n",
    "for i in misclassified:\n",
    "    #print('\\n','o',i,\" \",df.iloc[i,:],\" \",y[i])\n",
    "    print('\\n',df.iloc[i,:]['Species'])\n",
    "    #print('\\n',df.iloc[i,:],\" \",y[i])\n",
    "    print ('\\n')\n",
    "\n",
    "for i in misclassified: \n",
    "    print ('\\n', i,'classé en ',clf.predict(X)[i],'\\n')\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu d'apprentissage et de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm',\n",
    "         'PetalLengthCm', 'PetalWidthCm', \n",
    "         'Species']\n",
    "\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En classification, il est indispensable de créer un jeu d'apprentissage sur lequel un modèle est appris et un jeu de test pour évaluer le modèle.\n",
    "La fonction *train_test_split* permet de décomposer le jeu de données en 2 groupes : les données pour l'apprentissage et les données pour les tests.\n",
    "\n",
    "Le paramètre *train_size* indique la taille du jeu d'apprentissage qui sera utilisé.  \n",
    "le paramètre *random_state* spécifie un entier germe du nombre aléatoire pour le tirage. S'il n'est pas spécifié sickit learn utilise un générateur de nombre aléatoire à partir de np.random.   \n",
    "\n",
    "Depuis la version 0.21 il est également nécessaire de préciser la taille du jeu \n",
    "de test_size. De manière classique ce nombre est égal à la différence entre la taille du jeu de données - le test_size (1-test_size). Via cette fonctionnalité sickit learn permet de faire de l'échantillonage sur le jeu d'apprentissage.   \n",
    "\n",
    "Dans notre exemple nous prenons 30% du jeu de données comme jeu de test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'apprentissage du modèle se fait comme précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même pour la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy : 0.9428571428571428 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result = clf.predict(X_test)\n",
    "print('\\n accuracy :', accuracy_score(result, y_test),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème essentiel de cette approche est que le modèle est appris sur un seul jeu de données et qu'en fonction de la sélection les résultats peuvent être très différents.\n",
    "La bonne solution consiste à utiliser la **cross validation**.\n",
    "Dans notre cas, nous allons utiliser une 10-fold cross validation pour évaluer la qualité. \n",
    "Le jeu de données sera découpé en 10 partie, entrainé sur 9, testé sur 1 et cela sera répété pour toutes les combinaisons du découpage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed=7\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont : \n",
      " [0.8        0.86666667 1.         1.         0.93333333 1.\n",
      " 1.         1.         0.93333333 1.        ] \n",
      "\n",
      "Accuracy moyenne :  0.9533333333333334  standard deviation 0.06699917080747259\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, X, y, cv=k_fold, scoring=scoring)\n",
    "\n",
    "print('Les différentes accuracy pour les 10 évaluations sont : \\n',\n",
    "      score,'\\n')\n",
    "print ('Accuracy moyenne : ',score.mean(), \n",
    "       ' standard deviation', score.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'écart type (standard deviation) est très important car il montre les grandes variations qui peuvent exister par rapport aux jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible d'utiliser le **LeaveOneOut** (ou LOO) qui est une simple validation croisée. Chaque ensemble d'apprentissage est créé en prenant tous les échantillons sauf un, l'ensemble de test étant l'échantillon laissé de côté. Ainsi, pour les échantillons, nous avons différents ensembles d'apprentissages et différents ensembles de tests. Il est cependant préférable d'utiliser la **cross validation** qui offre de meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy en leaveoneout sont : \n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.] \n",
      "\n",
      "Accuracy moyenne :  0.9533333333333334  standard deviation 0.21092389359408498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "clf = GaussianNB()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, X, y, cv=loo, scoring=scoring)\n",
    "print('Les différentes accuracy en leaveoneout sont : \\n',\n",
    "      score,'\\n')\n",
    "print ('Accuracy moyenne : ',score.mean(), \n",
    "       ' standard deviation', score.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plus loin sur l'évaluation d'un modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy (nombre d'objets correctement classés) est la métrique la plus simple pour comprendre le \n",
    "résultat de la classification mais ne tient pas du tout compte de la distribution des données et ne permet pas d'indiquer les erreurs. Par exemple avec des classes très déséquilibrées (1 vs 99), nous pouvons avoir un modèle avec une accuracy de 99% mais lorsque qu'un objet de la classe intervient nous ne pouvons pas le retrouver.  \n",
    "\n",
    "Par la suite, par simplification, nous reprenons une classification réalisée sans cross validation mais le principe est évidemment le même avec cross validation. Nous introduisons la matrice de correlation et les différentes mesures : precision, rappel et F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy: 0.9428571428571428 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "result = clf.predict(X_test)\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion permet de connaître les objets bien ou mal classés. Il suffit d'utiliser la fonction *confusion_matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " matrice de confusion \n",
      " [[34  0  0]\n",
      " [ 0 33  5]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'obtenir plus d'information : *precision*, *recall* et  *f1-measure* à l'aide de *classification_report*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " matrice de confusion \n",
      " [[34  0  0]\n",
      " [ 0 33  5]\n",
      " [ 0  1 32]]\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        34\n",
      "Iris-versicolor       0.97      0.87      0.92        38\n",
      " Iris-virginica       0.86      0.97      0.91        33\n",
      "\n",
      "      micro avg       0.94      0.94      0.94       105\n",
      "      macro avg       0.95      0.95      0.94       105\n",
      "   weighted avg       0.95      0.94      0.94       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "print ('\\n',classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rappel** :  \n",
    "Considérons une matrice de confusion dans un cas binaire. Par exemple présence de SPAM ou non dans des mails.   \n",
    "\n",
    "  $$  \\begin{array}{|c|c|c|}\n",
    "  \\hline\n",
    "  N= & {\\bf PREDIT} & {\\bf PREDIT}  \\\\\n",
    "  115& {\\bf NON} & {\\bf OUI} \\\\\n",
    "  \\hline\n",
    "  {\\bf REEL} & 60 & 10 \\\\\n",
    "  {\\bf NON} & & \\\\\n",
    "  \\hline\n",
    " {\\bf REEL} & 5 & 40 \\\\\n",
    "  {\\bf OUI} & & \\\\\n",
    "  \\hline\n",
    "\\end{array}$$\n",
    "\n",
    "La matrice nous permet de voir qu'il y a deux classes prédites (OUI ou NON). Le classifieur fait un total de 115 prédictions. Sur ces 115 cas, le classifieur a prédit  OUI 50 fois et NON 65 fois. En fait 45 documents sont des SPAMS et 70 ne le sont pas. \n",
    "\n",
    "\n",
    "**TP** (True positive) : il s'agit des objets qui étaient prédits OUI (il s'agit de SPAM) et qui sont effectivement des SPAM.  \n",
    "**TN** (True negative) : il s'agit des objets qui étaient prédits NON (il ne s'agit pas de SPAM) et qui effectivement ne sont pas des SPAM.  \n",
    "**FP** (False positive) : il s'agit des objets qui étaient prédits comme SPAM mais qui en fait n'étaient pas des SPAM.  \n",
    "**FN** (False negative) : il s'agit des objets qui étaient prédits comme non SPAM qui en fait s'avèrent être des SPAM.  \n",
    "Dans la matrice ci-dessous ces éléments sont reportés :  \n",
    "\n",
    "$$  \\begin{array}{|c|c|c|c|}\n",
    "  \\hline\n",
    "  N= & {\\bf PREDIT} & {\\bf PREDIT} & \\\\\n",
    "  115& {\\bf NON} & {\\bf OUI} & \\\\\n",
    "  \\hline\n",
    "  {\\bf REEL} & TN=60 & FP=10 & 70\\\\\n",
    "  {\\bf NON} & & \\\\\n",
    "  \\hline\n",
    " {\\bf REEL} & FN=5 & TP=40 & 45\\\\\n",
    "  {\\bf OUI} & & \\\\\n",
    "  \\hline\n",
    "  & 65 & 50 &\\\\\n",
    "  \\hline\n",
    "\\end{array}$$\n",
    "\n",
    "L'**accuracy**  (ou justesse) correspond au pourcentage de prédiction correcte. Elle est définie par \n",
    "$$\\frac{TP+TN}{TN+FP+FN+TP}=\\frac{40+60}{60+10+5+40}=0.86.$$  \n",
    "Le **recall** (ou sensitivity ou True Positive Rate ou rappel) correspond au nombre d' objets pertinents retrouvés par rapport aux nombres d'objets pertinents du jeu de données. Dans notre cas, pour tous les OUI présents combien de fois le OUI a t'il été prédit ?\n",
    "\n",
    "$$recall=\\frac{Nombre\\ de\\ SPAM\\ correctement\\ reconnus}{Nombre\\ total\\ de\\ SPAM\\ dans\\ le\\ jeu\\ de\\ données} = \\frac{TP}{FN+TP}=\\frac{40}{40+5}=0.88.$$  \n",
    "La **precision** correspond à la proportion d'objets pertinents parmi les objets sélectionné. Tous les objets retournés non pertinents constituent du bruit. \n",
    "$$precision=\\frac{Nombre\\ de\\ SPAM\\ correctement\\ reconnus}{Nombre\\ de\\ fois\\ où\\ un\\ objet\\ a\\ été\\ prédit\\ SPAM} = \\frac{TP}{TP+FP}=\\frac{40}{40+10}=0.8.$$  \n",
    "\n",
    "Le **f1-score** (ou f-measure) est la moyenne harmonique du rappel et de la précision.\n",
    "$$f1-score=2\\times\\frac{precision \\times recall}{precision + recall}=2\\times\\frac{0.8 \\times 0.88}{0.8+0.88}.$$  \n",
    "\n",
    "Dans le cas d'une classification multiclasse, à partir de la matrice de confusion, la precision est calculée, pour une colonne $i$, par :  \n",
    "$$precision_i = \\frac{M_{ii}}{\\sum_j M_{ji}}$$\n",
    "et le recall par : \n",
    "$$ recall_i = \\frac{M_{ii}}{\\sum_j M_{ij}}$$  \n",
    "\n",
    "Pour la matrice de confusion suivante : \n",
    "\\begin{array}{cccc}\n",
    "Iris-setosa &34 & 0 & 0\\\\\n",
    "Iris-versicolor & 0 &33 & 5\\\\\n",
    "Iris-virginica & 0 & 1 &32\\\\\n",
    "\\end{array}\n",
    "\n",
    "classification_report retourne le résultat suivant :  \n",
    "\n",
    " \\begin{array}{ccccc}\n",
    "           &   precision  &  recall & f1-score &  support\\\\\n",
    "\\\\\n",
    "    Iris-setosa    &   1.00  &    1.00  &    1.00   &     34\\\\\n",
    "Iris-versicolor   &    0.97 &     0.87  &    0.92  &      38\\\\\n",
    " Iris-virginica   &    0.86  &    0.97  &    0.91  &      33\\\\\n",
    "\\\\\n",
    "    avg / total    &   0.95  &    0.94  &    0.94   &    105\\\\\n",
    "\\end{array}    \n",
    "\n",
    "La precision d'Iris-versicolor est obtenue par : \n",
    "$$precision_i = \\frac{M_{ii}}{\\sum_j M_{ji}}=\\frac{33}{33+1}=0.97.$$\n",
    "Le rappel d'Iris-versicolor est obtenue par : \n",
    "$$ recall_i = \\frac{M_{ii}}{\\sum_j M_{ij}}=\\frac{33}{33+5}=0.87.$$\n",
    "La precision d'Iris-virginica est obtenue par : \n",
    "$$precision_i = \\frac{M_{ii}}{\\sum_j M_{ji}}=\\frac{32}{32+5}=0.86.$$\n",
    "Le rappel d'Iris-versicolor est obtenue par : \n",
    "$$ recall_i = \\frac{M_{ii}}{\\sum_j M_{ij}}=\\frac{32}{32+1}=0.96.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le cas particulier de la classification binaire **  \n",
    "\n",
    "Dans le cas de la classification binaire, il est également possible d'utiliser la courbre ROC (*Receiver operating characteristic*). Il s'agit d'un graphique qui représente les performances d'un modèle de classification (tracé des vrais positifs en fonction du taux de faux positifs).  \n",
    "\n",
    "Le taux de vrais positifs correspond au rappel (*recall*) : \n",
    "$$TTP = \\frac{TP}{FN+TP}$$  \n",
    "Le taux de faux positifs correspond à :  \n",
    "$$TFP = \\frac{FP}{FP+TP}$$\n",
    "est un graphique représentant les performances d'un modèle de classification pour tous les seuils de classification. Cette courbe trace le taux de vrais positifs en fonction du taux de faux positifs :\n",
    "\n",
    "Taux de vrais positifs\n",
    "Taux de faux positifs\n",
    "Le taux de vrais positifs (TVP) est l'équivalent du rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.797101\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Make it a binary classification problem by removing the third class\n",
    "X, y = X[y != 2], y[y != 2]\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "half = int(n_samples / 2)\n",
    "X_train, X_test = X[:half], X[half:]\n",
    "y_train, y_test = y[:half], y[half:]\n",
    "\n",
    "# Run classifier\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"Area under the ROC curve : %f\" % roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Receiver operating characteristic example')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour connaître les objets mal classés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les objets mal classés sont :\n",
      "\n",
      " 52     Iris-versicolor\n",
      "56     Iris-versicolor\n",
      "70     Iris-versicolor\n",
      "77     Iris-versicolor\n",
      "83     Iris-versicolor\n",
      "106     Iris-virginica\n",
      "119     Iris-virginica\n",
      "Name: Species, dtype: object\n",
      "\n",
      "\n",
      "\n",
      " [ 52  56  70  77  83 106 119] classé en  ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "misclassified = np.where(y != clf.predict(X))\n",
    "\n",
    "print('Les objets mal classés sont :')\n",
    "\n",
    "i=0\n",
    "for i in misclassified:\n",
    "    print('\\n',df.iloc[i,:]['Species'])\n",
    "    print ('\\n')\n",
    "\n",
    "for i in misclassified: \n",
    "    print ('\\n', i,'classé en ',clf.predict(X)[i],'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher, avec seaborn, la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Iris-setosa', 'Iris-versicolor','Iris-virginica']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "hm = sns.heatmap(conf, \n",
    "                 ax=ax,           # Axes où afficher\n",
    "                 xticklabels=labels, #labels sur les x\n",
    "                 yticklabels=labels, #labels sur les colonnes\n",
    "                 cmap=\"YlGnBu\", # Couleur\n",
    "                 square=True,    # Si True, toutes les cellules \n",
    "                                 #ont le même aspect carré\n",
    "                 annot=True      # Pour afficher les valeurs\n",
    "                )\n",
    "fig.suptitle('GaussianNB\\nAccuracy:{0:.3f}'.format(accuracy_score(result,y_test)), \n",
    "              fontsize=12, \n",
    "              fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les métriques peuvent être appelées indépendamment. Par exemple   \n",
    "*from sklearn.metrics import precision_score  \n",
    "print(\"Precision score: {}\".format(precision_score(y_true,y_pred)))*   \n",
    "ou à l'aide de la fonction *precision_recall_fscore_support*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [1.         0.97058824 0.86486486]\n",
      "recall: [1.         0.86842105 0.96969697]\n",
      "fscore: [1.         0.91666667 0.91428571]\n",
      "support: [34 38 33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, result)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser plusieurs classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme l'indique le NO FREE LUNCH THEOREM il n'existe pas un classifieur universel et en fonction des données il est souvent nécessaire d'en évaluer plusieurs pour retenir le plus efficace. Le principe est similaire au précédent, il suffit de les mettre dans une structure et de boucler dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation des données\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=validation_size, random_state=seed,test_size=testsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple, nous utilison LogisticRegression, DecisionTree, KNeighbors, GaussianNB et SVM.   \n",
    "Les paramètres utilisés pour chacune des approches sont ceux par défaut. \n",
    "Pour chaque approche nous faisons une cross validation de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time pour LR   0.1513993740081787\n",
      "LR: 0.900000 (0.116428)\n",
      "Time pour KNN   0.01901412010192871\n",
      "KNN: 0.933333 (0.084327)\n",
      "Time pour CART   0.01136636734008789\n",
      "CART: 0.946667 (0.065320)\n",
      "Time pour NB   0.018451929092407227\n",
      "NB: 0.946667 (0.058119)\n",
      "Time pour SVM   0.012649774551391602\n",
      "SVM: 0.953333 (0.052068)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    start_time = time.time()\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    #pour avoir les paramètres utilisés dans le modèle enlever commentaire ligne suivante\n",
    "    #print (model.get_params())\n",
    "    print (\"Time pour\",name,\" \",time.time() - start_time)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'LR'),\n",
       " Text(0, 0, 'KNN'),\n",
       " Text(0, 0, 'CART'),\n",
       " Text(0, 0, 'NB'),\n",
       " Text(0, 0, 'SVM')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGlxJREFUeJzt3X2UXXV97/H3hwBBBHEwI5U8osQ2ECzoNHiXUcLlKSIaHmpNFAWbe6N3CbY81ILhXmIkhbpEuN6LYmjSSFsTUlrbuK69kZakkAolkxLQJDwkAUwCaEICiHAhCd/7x/4Ns3OYmXMmc2bOmfl9Xmudlb3377f3/u69z3zOPnufc6KIwMzM8nBAowswM7OB49A3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9+aiqR1kqY0cP3jJIWkAwdwnYskXddPy/6MpJ/00D5F0tb+WLc1J4f+ICXp05LaJb0k6RlJ/yRpcqPr6quIOD4iVja6jqEiIv4mIs7sGE8vaMc2siZrLIf+ICTpcuBm4M+Ao4AxwHeAaY2sq5qBPHs272/rmkN/kJF0BDAX+FJE/H1E/CYidkfEjyLiT1Kf4ZJulvR0etwsaXhqmyJpq6SvSPpVepdwrqSzJT0maaekr5bWN0fSnZLukPRrSf8h6XdL7VdJ2pTa1ks6r9R2saR/k3STpOeAOZLeI+luSc9J2iHpbyS9vTTPk5JOT8OT0ruZFyX9UtK3Sv0+kS4FPS9ppaQJFcu4UtLDkl5ItR/Szf4cJumbqZbNwMcq97ekBWk/bZN0naRhqe1YSf+a1rFD0h09HLe/lfRs6nuPpON76PuVtL6nJf2X8tl5qud2SdslPSXpGkkH9LC/L5a0KrXfk1bxUHqH+KnSOq8oPR8+X5q+SNJ30jvJl9Lyfys9p3ZJekTSSaX+R0v6u1TfE5K+XGrr9njaAIoIPwbRA5gK7AEO7KHPXOB+4J1AK/BT4OupbUqa/38ABwH/FdgO/AA4HDgeeAU4JvWfA+wGfj/1vxJ4AjgotX8SOJriBOJTwG+Ad6W2i9O6LgUOBN4CHAucAQxPtd0D3Fyq/Ung9DR8H/DZNHwY8ME0/N60njNSTV8BNgIHl5bxQKrrSGAD8MVu9tUXgUeA0anvCiA69i/wQ+B7wFvT/nwA+EJqWwzMTtt+CDC5h2Pyh2n/Dqd4l7a21LYIuK50fJ9Nx+FQ4K9TPcem9tuBf0zLGgc8BszsYX9fDKwqreuNZVU8H+amfXk28DLQUqptB/CBtI13p+P/OWAYcB2wIvU9AFhD8dw6GHg3sBk4q6fj6ccAZ0ijC/CjlwcMPgM8W6XPJuDs0vhZwJNpeApFqA9L44enIDi51H8NcG4angPcX2o7AHgG+HA3614LTEvDFwO/qFLrucCDpfEn6Qz9e4CvASMq5vnvwNKKmrYBU0rLuLDU/g3g1m7WfzelFwTgzLQ/DqS4dPYq8JZS+4xSyN0OzAdG9fIYvj2t44g0vojO0F8IXF/qe2xHUKeQfQ04rtT+BWBld/ub2kL/FUonEcCv6HyBXQTcVmq7FNhQGj8BeD4Nn9zF+q8G/rKn4+nHwD58eWfweQ4YUeV67dHAU6Xxp9K0N5YREXvT8Cvp31+W2l+hOBPrsKVjICJeB7Z2LE/S5yStTZdZngcmAiO6mjf1P0rSknSp5EWKM9ly/7KZFGf1j0haLemcrrYv1bQFGFma99nS8MsV21N2dEWN5f02luLs95nS9n2P4owfincYAh5Il5r+sKsVpEtIN6TLYC9SvChB19tdWU95eESqp/LYjuymf62ei4g9pfHK/VX53OjuuTIWOLpjX6X99VWKF0/o/njaAPKNnsHnPoqzz3OBO7vp8zTFH+C6ND4mTdtfozsG0vXjUcDTksYCtwGnAfdFxF5JaymCsEPlz7j+WZp2QkTslHQu8L+7WmlEPA7MSOs8H7hT0jvStpxQqkmpxm37sW3PlLePYl912EKxr0dUhGJHfc9SXB5DxSen/lnSPRGxsaLrpylusp9OEfhHALvYdz+V6xlVGi/XtoPiUttYYH2p3vJ2N/Jnc7cAT0TE+K4auzueEfGbgSwydz7TH2Qi4gWKa6a3qLgBe6ikgyR9VNI3UrfFwDWSWiWNSP3/ug+r/YCk89O7iz+mCML7Ka5zB8U9AdINwIlVlnU48BLwgqSRwJ9011HShZJa05n882ny68BS4GOSTpN0EHBFqumn+7FtS4EvSxolqQW4qqMhIp4BfgLcKOltkg5QcSP6lFTfJyV1BPQuin3xejfb/CrFu7RDKV74eqrn85ImSDqU4lJWRz17U/s8SYenF93L6d2x/SXFtfb+8ADwa0l/Kukt6R3OREm/Bz0eTxtADv1BKCJupPhjv4YicLcAlwD/kLpcB7QDDwM/A/4jTdtf/0hxk3YX8Fng/Cg+MbQeuJHi3ccvKc6+/63Ksr4GvB94Afg/wN/30HcqsE7SS8D/BKZHxCsR8ShwIfC/KM5+Pw58PCJe249tuw1YDjxEsZ8q6/kcxU3J9RTbfyfwrtT2e8C/p/qWAX8UEZu7WMftFJdhtqXl3N9dMRHxT8C3KW4obyz1fTX9eynFTezNwCqKG/ALa9tUoLhH8/10+eUPejFfVelF6RzgRIqbvTuAv6B4ZwPdHM961mDVKd1gMeuSpDkUN/4ubHQtOVLxUdSfA8O7usRk1ls+0zdrMpLOU/Fdixbgz4EfOfCtXhz6Zs3nCxQfm9wE7AX+W2PLsaHEl3fMzDLiM30zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMtJ0/zH6iBEjYty4cY0uw8xsUFmzZs2OiGit1q/pQn/cuHG0t7c3ugwzs0FF0lO19PPlHTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjFQNfUkLJf1K0s+7aZekb0vaKOlhSe8vtV0k6fH0uKiehZuZWe/Vcqa/CJjaQ/tHgfHpMQv4LoCkI4FrgZOBScC1klr6UqyZmfVN1dCPiHuAnT10mQbcHoX7gbdLehdwFnBXROyMiF3AXfT84mFmZv2sHl/OGglsKY1vTdO6m/4mkmZRvEtgzJgxfS7oyCOPZNeuXX1eTl+1tLSwc2dPr5cDYM4RjV1/2ZwXGrp6Py86eV90ym1fNMU3ciNiPjAfoK2tLfq6vF27dhHR58X0maRGl4C+9mLT7IuY09ga/Lzo5H3RKbd9UY9P72wDRpfGR6Vp3U03M7MGqUfoLwM+lz7F80HghYh4BlgOnCmpJd3APTNNMzOzBql6eUfSYmAKMELSVopP5BwEEBG3Aj8GzgY2Ai8Dn09tOyV9HVidFjU3Ihp8gdvMLG9VQz8iZlRpD+BL3bQtBBbuX2lmZlZv/kaumVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZUTFf3HbPNra2qK9vb1vC5lzRH2KqYc5LzR09ZJohmPcFHX4eVFav/dF5/qHxr6QtCYi2qr2a/gfYoV6hH5TBEyT1NEMNTRLHc1QQ7PU0Qw1NEsdzVBDPeqoNfR9ecfMLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwyUlPoS5oq6VFJGyVd1UX7WEn/IulhSSsljSq17ZW0Nj2W1bN4MzPrnQOrdZA0DLgFOAPYCqyWtCwi1pe6fRO4PSK+L+k/A9cDn01tr0TEiXWu28zM9kMtZ/qTgI0RsTkiXgOWANMq+hwH3J2GV3TRbmZmTaCW0B8JbCmNb03Tyh4Czk/D5wGHS3pHGj9EUruk+yWd29UKJM1Kfdq3b9/ei/LNzKw36nUj90rgFEkPAqcA24C9qW1s+j2ITwM3S3pP5cwRMT8i2iKirbW1tU4lmZlZparX9CkCfHRpfFSa9oaIeJp0pi/pMOCCiHg+tW1L/26WtBI4CdjU58rNzKzXajnTXw2Ml3SMpIOB6cA+n8KRNEJSx7KuBham6S2Shnf0AT4ElG8Am5nZAKoa+hGxB7gEWA5sAJZGxDpJcyV9InWbAjwq6THgKGBemj4BaJf0EMUN3hsqPvVjZmYDyL+n34+aoY5mqKFZ6miGGpqljmaooVnqaIYa6lGHf0/fzMzexKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUZq+RkGsyFDUqNLoKWlpdElWIWcnhcOfctGPb6A0yxf5LH6ye154cs7ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlpGaQl/SVEmPStoo6aou2sdK+hdJD0taKWlUqe0iSY+nx0X1LN7MzHqnauhLGgbcAnwUOA6YIem4im7fBG6PiPcBc4Hr07xHAtcCJwOTgGslDcx/+W5mZm9Sy5n+JGBjRGyOiNeAJcC0ij7HAXen4RWl9rOAuyJiZ0TsAu4Cpva9bDMz2x+1hP5IYEtpfGuaVvYQcH4aPg84XNI7apwXSbMktUtq3759e621m5lZL9XrRu6VwCmSHgROAbYBe2udOSLmR0RbRLS1trbWqSQzM6t0YA19tgGjS+Oj0rQ3RMTTpDN9SYcBF0TE85K2AVMq5l3Zh3rNzKwPajnTXw2Ml3SMpIOB6cCycgdJIyR1LOtqYGEaXg6cKakl3cA9M00zM7MGqBr6EbEHuIQirDcASyNinaS5kj6Ruk0BHpX0GHAUMC/NuxP4OsULx2pgbppmZmYNoIhodA37aGtri/b29j4tQxLNsF3NUEcz1NBMdfSVt2No1tFXzbAdktZERFu1fv5GrplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWWklp9hMLMhSFKjS6Clxb+0PtAc+mYZqscXiZrhC0nWe768Y2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlG/DMMGfBvrNSm1v1Urd9Q+GkC74tOQ21fOPSHOP/GSu1y2MZaeV90Gmr7wpd3zMwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCM1hb6kqZIelbRR0lVdtI+RtELSg5IelnR2mj5O0iuS1qbHrfXeADMzq13VL2dJGgbcApwBbAVWS1oWEetL3a4BlkbEdyUdB/wYGJfaNkXEifUt28zM9kctZ/qTgI0RsTkiXgOWANMq+gTwtjR8BPB0/Uo0M7N6qSX0RwJbSuNb07SyOcCFkrZSnOVfWmo7Jl32+VdJH+5qBZJmSWqX1L59+/baqzczs16p143cGcCiiBgFnA38laQDgGeAMRFxEnA58ANJb6ucOSLmR0RbRLS1trbWqSQzM6tUS+hvA0aXxkelaWUzgaUAEXEfcAgwIiJejYjn0vQ1wCbgvX0t2szM9k8tob8aGC/pGEkHA9OBZRV9fgGcBiBpAkXob5fUmm4EI+ndwHhgc72KNzOz3qn66Z2I2CPpEmA5MAxYGBHrJM0F2iNiGXAFcJukyyhu6l4cESHpI8BcSbuB14EvRsTOftsaMzPrkZrtt6Lb2tqivb29T8tolt9/b5Y6+mqobIfZUCZpTUS0Vevnb+SamWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZqSn0JU2V9KikjZKu6qJ9jKQVkh6U9LCks0ttV6f5HpV0Vj2LNxsoixcvZuLEiQwbNoyJEyeyePHiRpdktl8OrNZB0jDgFuAMYCuwWtKyiFhf6nYNsDQivivpOODHwLg0PB04Hjga+GdJ742IvfXeELP+snjxYmbPns2CBQuYPHkyq1atYubMmQDMmDGjwdWZ9U4tZ/qTgI0RsTkiXgOWANMq+gTwtjR8BPB0Gp4GLImIVyPiCWBjWp7ZoDFv3jwWLFjAqaeeykEHHcSpp57KggULmDdvXqNLM+u1qmf6wEhgS2l8K3ByRZ85wE8kXQq8FTi9NO/9FfOOrFyBpFnALIAxY8bUUrfVkaQ+94mIepXTdDZs2MDkyZP3mTZ58mQ2bNjQoIrM9l+9buTOABZFxCjgbOCvJNW87IiYHxFtEdHW2tpap5KsVhHR58dQNmHCBFatWrXPtFWrVjFhwoQGVWS2/2oJ5m3A6NL4qDStbCawFCAi7gMOAUbUOK9ZU5s9ezYzZ85kxYoV7N69mxUrVjBz5kxmz57d6NLMeq2WyzurgfGSjqEI7OnApyv6/AI4DVgkaQJF6G8HlgE/kPQtihu544EH6lS72YDouFl76aWXsmHDBiZMmMC8efN8E9cGpaqhHxF7JF0CLAeGAQsjYp2kuUB7RCwDrgBuk3QZxU3di6N4z79O0lJgPbAH+JI/uWOD0YwZMxzyNiSo2a7HtrW1RXt7e5+WIakprjM3Sx1mNvRJWhMRbdX6+Ru5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlpGq/zH6YCWp0SXQ0tLS6BLMzPYxJEO/Hv8Zuf9TczMbinx5x8wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDJSU+hLmirpUUkbJV3VRftNktamx2OSni+17S21Latn8WZm1jtVv5wlaRhwC3AGsBVYLWlZRKzv6BMRl5X6XwqcVFrEKxFxYv1KNjOz/VXLmf4kYGNEbI6I14AlwLQe+s8AFtejODMzq69aQn8ksKU0vjVNexNJY4FjgLtLkw+R1C7pfknn7nelZmbWZ/X+7Z3pwJ0Rsbc0bWxEbJP0buBuST+LiE3lmSTNAmYBjBkzps4lmZlZh1rO9LcBo0vjo9K0rkyn4tJORGxL/24GVrLv9f6OPvMjoi0i2lpbW2soyczM9kctob8aGC/pGEkHUwT7mz6FI+l3gBbgvtK0FknD0/AI4EPA+sp5zcxsYFS9vBMReyRdAiwHhgELI2KdpLlAe0R0vABMB5bEvr9HPAH4nqTXKV5gbih/6sfMzAaWmu0349va2qK9vb3RZfj39M1sUJG0JiLaqvXzN3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsI/X+7Z1BQ1Kf+/hz/GY22GQb+g5sM8uRL++YmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZabr/OUvSduCpRtcBjAB2NLqIJuF90cn7opP3Radm2BdjI6K1WqemC/1mIam9lv96LAfeF528Lzp5X3QaTPvCl3fMzDLi0Dczy4hDv3vzG11AE/G+6OR90cn7otOg2Re+pm9mlhGf6ZuZZcShD0h6qYtpcyRtk7RW0npJMxpRW38qb7eksyU9Jmls2vaXJb2zm74h6cbS+JWS5gxY4XUk6bckLZG0SdIaST+W9N7U9seS/p+kI0r9p0h6IT0vHpH0zTT982naWkmvSfpZGr6hUdtWLz0d74q/k0ckfVfSkMoVSbMlrZP0cNrOayVdX9HnREkb0vCTku6taF8r6ecDWXd3htTB6Qc3RcSJwDTge5IOanRB/UHSacC3gY9GRMd3JHYAV3Qzy6vA+ZJGDER9/UXFf432Q2BlRLwnIj4AXA0clbrMAFYD51fMem96XpwEnCPpQxHxlxFxYpr+NHBqGr9qYLamX1U73h1/J8cBJwCnDFhl/UzSfwLOAd4fEe8DTgdWAJ+q6DodWFwaP1zS6LSMCQNRa60c+jWIiMeBl4GWRtdSb5I+AtwGnBMRm0pNC4FPSTqyi9n2UNy4umwASuxPpwK7I+LWjgkR8VBE3CvpPcBhwDUU4f8mEfEKsBYYORDFNlCtx/tg4BBgV79XNHDeBeyIiFcBImJHRNwD7JJ0cqnfH7Bv6C+l84VhRkVbQzn0ayDp/cDjEfGrRtdSZ8OBfwDOjYhHKtpeogj+P+pm3luAz5QvfQxCE4E13bRNB5YA9wK/Lemoyg6SWoDxwD39VmHz6Ol4XyZpLfAM8FhErB3Y0vrVT4DR6dLndyR1vItZTPEcQdIHgZ3p5LDD39H5DvHjwI8GquBqHPo9u0zSOuDfgXmNLqYf7AZ+Cszspv3bwEWSDq9siIgXgduBL/dfeQ01A1gSEa9T/AF/stT2YUkPAduA5RHxbCMKHEhVjnfH5Z13Am+VNH1Ai+tHEfES8AFgFrAduEPSxcAdwO+n+xeVl3YAnqN4NzAd2EBxpaApOPR7dlNEHA9cACyQdEijC6qz1ynelk6S9NXKxoh4HvgB8KVu5r+Z4gXjrf1WYf9aR/EHvQ9JJ1Ccwd8l6UmKP+ryJZ57I+J3geOBmZJOHIBam0GPxzsidgP/F/jIQBbV3yJib0SsjIhrgUuACyJiC/AExf2LCyheBCrdQfEOqWku7YBDvyYRsQxoBy5qdC31FhEvAx+jeOve1Rn/t4AvAAd2Me9OimuX3b1TaHZ3A8MlzeqYIOl9FO9w5kTEuPQ4Gjha0tjyzBHxBHAD8KcDWXSjVDve6cb4h4BNXbUPRpJ+W9L40qQT6fxByMXATcDmiNjaxew/BL4BLO/fKnvHoV84VNLW0uPyLvrMBS4fah9Hgzf+mKcC10j6REXbDoon7/BuZr+R4hcGB50ovpl4HnB6+sjmOuB6YArFNpf9kHQNt8KtwEckjeu/SptKV8e745r+z4FhwHcGvKr+cxjw/fSx7YcpPqE0J7X9LcW7vS7P5CPi1xHx5xHx2oBUWiN/I9fMLCND7qzVzMy659A3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjPx/VYcsWLjPVlgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme SVM donne des meilleurs résultats, nous pouvons l'utiliser comme modèle de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy:  0.9619047619047619 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[34  0  0]\n",
      " [ 0 34  4]\n",
      " [ 0  0 33]]\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        34\n",
      "Iris-versicolor       1.00      0.89      0.94        38\n",
      " Iris-virginica       0.89      1.00      0.94        33\n",
      "\n",
      "      micro avg       0.96      0.96      0.96       105\n",
      "      macro avg       0.96      0.96      0.96       105\n",
      "   weighted avg       0.97      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "result = clf.predict(X_test)\n",
    "\n",
    "print('\\n accuracy: ', accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "print ('\\n',classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les hyperparamètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'approche précédente nous avons pris les valeurs par défaut pour les différents classifieurs. Cependant en fonction des paramètres du classifieur les résultats peuvent être complétement différents (choix du noyeau SVM, nombre de K dans KNeighbors, etc. ). Sikit learn permet de pouvoir faire une recherche exhaustive (grid search) pour trouver les paramètres les plus pertinents pour un classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation des données\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=validation_size, \n",
    "                                                    random_state=seed,\n",
    "                                                    test_size=testsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons un arbre de décision. Les principaux paramètres sont le critère pour découper (gini ou entropy), la profondeur maximale de l'arbre, et le nombre d'échantillons par feuille. Il faut, dans un premier temps, initialiser les variables à tester dans un dictionnaire.  \n",
    "Le test de toutes les valeurs se fait à l'aide de la fonction *GridSearchCV*.\n",
    "Ele prend commme paramètre le classifieur, le dictionnaire ds paramètre, le type de scoring, le nombre de crossvalidation.  \n",
    "\n",
    "Quelques paramètres souvent utilisés :  \n",
    "-  *n_jobs* : (par défaut 1) nombre de coeurs à utiliser pour effectuer les calculs, dépend du cpu. Si la machine possède plusieurs coeurs, il est possible d'indiquer de tous les utiliser en mettant *n_jobs=-1*  \n",
    "-  *verbose* : affichage du déroulement des calculs, 0 = silent.\n",
    "- *random_state* : si le classifieur utilisé utilise de l'aléatoire, random_state permet de fixer le générateur pour reproduire les résultats.   \n",
    "\n",
    "\n",
    "Un grid search est long à obtenir dans la mesure où il faut essayer l'ensemble des cas. La possibilité de répartir sur plusieurs processeur permet de faire gagner beaucoup de temps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param = {  \n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10]\n",
    "}\n",
    "\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=DecisionTreeClassifier(),  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1,\n",
    "                    iid=True,\n",
    "                    return_train_score=True)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour connaître les meilleures conditions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meilleur score  0.9777777777777777 \n",
      "\n",
      "meilleurs paramètres {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1} \n",
      "\n",
      "meilleur estimateur DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('meilleur score ',gd_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', gd_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',gd_sr.best_estimator_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meilleur score  1.0 \n",
      "\n",
      "meilleurs paramètres {'metric': 'minkowski', 'n_neighbors': 1} \n",
      "\n",
      "meilleur estimateur KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "           weights='uniform') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "grid_param = {  \n",
    "    'n_neighbors': list(range(1,15)),\n",
    "    'metric': ['minkowski','euclidean','manhattan']\n",
    "}\n",
    "                        \n",
    "gd_sr = GridSearchCV(estimator=KNeighborsClassifier(),  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1,\n",
    "                    iid=True,\n",
    "                    return_train_score=True)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "\n",
    "print ('meilleur score ',gd_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', gd_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',gd_sr.best_estimator_,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meilleur score  1.0 \n",
      "\n",
      "meilleurs paramètres {'C': 1, 'gamma': 0.001, 'kernel': 'linear'} \n",
      "\n",
      "meilleur estimateur SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "grid_param = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "    'gamma' : [0.001, 0.01, 0.1, 1], \n",
    "    'kernel': ['linear','rbf']}\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=SVC(),  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=1,\n",
    "                     iid=True,\n",
    "                    return_train_score=True)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "\n",
    "print ('meilleur score ',gd_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', gd_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',gd_sr.best_estimator_,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour voir l'ensemble des évaluations effectuées par GridSearchCV : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.136679</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.136679</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.136679</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.136679</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.452069</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.136679</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.000950         0.000479         0.444444          0.452069   0.001   \n",
       "1       0.000517         0.000292         0.444444          0.452069   0.001   \n",
       "2       0.000436         0.000277         0.444444          0.452069   0.001   \n",
       "3       0.000468         0.000308         0.444444          0.452069   0.001   \n",
       "4       0.000377         0.000345         0.444444          0.452069   0.001   \n",
       "\n",
       "  param_gamma param_kernel                                            params  \\\n",
       "0       0.001       linear  {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "1       0.001          rbf     {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "2        0.01       linear   {'C': 0.001, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "3        0.01          rbf      {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "4         0.1       linear    {'C': 0.001, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "\n",
       "   rank_test_score  split0_test_score       ...         split2_test_score  \\\n",
       "0               26           0.363636       ...                     0.375   \n",
       "1               26           0.363636       ...                     0.375   \n",
       "2               26           0.363636       ...                     0.375   \n",
       "3               26           0.363636       ...                     0.375   \n",
       "4               26           0.363636       ...                     0.375   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.378378              0.375            0.378378   \n",
       "1            0.378378              0.375            0.378378   \n",
       "2            0.378378              0.375            0.378378   \n",
       "3            0.378378              0.375            0.378378   \n",
       "4            0.378378              0.375            0.378378   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0              0.375            0.378378      0.000347        0.000152   \n",
       "1              0.375            0.378378      0.000163        0.000024   \n",
       "2              0.375            0.378378      0.000064        0.000014   \n",
       "3              0.375            0.378378      0.000113        0.000052   \n",
       "4              0.375            0.378378      0.000019        0.000112   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.136679         0.145402  \n",
       "1        0.136679         0.145402  \n",
       "2        0.136679         0.145402  \n",
       "3        0.136679         0.145402  \n",
       "4        0.136679         0.145402  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# convertion en DataFrame\n",
    "results = pd.DataFrame(gd_sr.cv_results_) \n",
    "# Affichage des 5 premières lignes\n",
    "display(results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantage de GridSearchCV est qu'il va parcourir toutes les conditions et retourner celles qui sont les meilleures pour la ou les mesures de scoring recherchée (dans notre cas nous avons privilégié l'accuracy).\n",
    "Cela est très pratique mais est malheureusement impossible dans certains cas car beaucoup trop long à mettre en place.\n",
    "Une solution possible est d'utiliser *RandomizedSearchCV* qui parcourt de manière aléatoire l'espace de recherche. \n",
    "Il suffit dans ce cas de spécifier des tirages aléatoires pour les valeurs possibles des paramètres et de préciser le nombre d'itérations voulues.\n",
    "Le second usage de *RandomizedSearchCV* est, lorsque l'on n'a pas une très bonne idée de ce que cela peut donner ou des paramètres à utiliser de faire appel à lui pour avoir des valeurs qui peuvent être significatives et de faire suivre à partir de ces valeurs une recherche via *GridSearchCV*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meilleur score  0.9555555555555556 \n",
      "\n",
      "meilleurs paramètres {'criterion': 'entropy', 'max_depth': 16, 'min_samples_leaf': 1} \n",
      "\n",
      "meilleur estimateur DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=16,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733136</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12, 'min...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733136</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 16, 'min...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733136</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 14, 'min...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.000518         0.000348         0.733333          0.733136   \n",
       "1       0.000512         0.000590         0.733333          0.733136   \n",
       "2       0.000421         0.000315         0.955556          1.000000   \n",
       "3       0.000503         0.000392         0.733333          0.733136   \n",
       "4       0.000288         0.000228         0.955556          1.000000   \n",
       "\n",
       "  param_criterion param_max_depth param_min_samples_leaf  \\\n",
       "0         entropy              12                     13   \n",
       "1            gini              10                     12   \n",
       "2         entropy              16                      1   \n",
       "3            gini               2                     13   \n",
       "4         entropy              14                      7   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'criterion': 'entropy', 'max_depth': 12, 'min...                9   \n",
       "1  {'criterion': 'gini', 'max_depth': 10, 'min_sa...                9   \n",
       "2  {'criterion': 'entropy', 'max_depth': 16, 'min...                1   \n",
       "3  {'criterion': 'gini', 'max_depth': 2, 'min_sam...                9   \n",
       "4  {'criterion': 'entropy', 'max_depth': 14, 'min...                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0             0.7500            0.724138           0.733333   \n",
       "1             0.7500            0.724138           0.733333   \n",
       "2             0.9375            1.000000           0.933333   \n",
       "3             0.7500            0.724138           0.733333   \n",
       "4             0.9375            1.000000           0.933333   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.733333           0.714286            0.741935      0.000051   \n",
       "1            0.733333           0.714286            0.741935      0.000065   \n",
       "2            1.000000           1.000000            1.000000      0.000056   \n",
       "3            0.733333           0.714286            0.741935      0.000145   \n",
       "4            1.000000           1.000000            1.000000      0.000023   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000074        0.014548         0.007267  \n",
       "1        0.000243        0.014548         0.007267  \n",
       "2        0.000025        0.029918         0.000000  \n",
       "3        0.000063        0.014548         0.007267  \n",
       "4        0.000011        0.029918         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "rand_param = {  \n",
    "    'max_depth': randint(1, 20),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': randint(1, 20)\n",
    "}\n",
    "\n",
    "\n",
    "rand_sr = RandomizedSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                             param_distributions = rand_param, \n",
    "                             random_state=1, \n",
    "                             n_iter=20, \n",
    "                             cv=3, \n",
    "                             n_jobs=-1,\n",
    "                             scoring='accuracy',\n",
    "                             iid=True,\n",
    "                             return_train_score=True)\n",
    "\n",
    "rand_sr.fit(X_train, y_train)  \n",
    "\n",
    "print ('meilleur score ',rand_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', rand_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',rand_sr.best_estimator_,'\\n')\n",
    "\n",
    "# convertion en DataFrame\n",
    "results = pd.DataFrame(rand_sr.cv_results_) \n",
    "# Affichage des 5 premières lignes\n",
    "display(results.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch et plusieurs classifieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est tout à fait possible d'utiliser Gridsearch avec plusieurs classifieurs. Il suffit pour cela d'initaliser les classifiers dans un biblitothèse et faire de même pour les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifiers = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params = {'KNeighborsClassifier' : [{'n_neighbors': list(range(1,15))},\n",
    "    {'metric': ['minkowski','euclidean','manhattan']}],\n",
    "           'DecisionTreeClassifier': [{'max_depth': [1,2,3,4,5,6,7,8,9,10]},\n",
    "    {'criterion': ['gini', 'entropy']},\n",
    "    {'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10]}],\n",
    "       'SVC':[{'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "    'gamma' : [0.001, 0.01, 0.1, 1], \n",
    "    'kernel': ['linear','rbf']}]  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le meilleur resultat : \n",
      "\n",
      "Classifier :  KNeighborsClassifier  score 1.00  avec  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "Tous les résultats : \n",
      "\n",
      "Classifier :  KNeighborsClassifier  score 1.00  avec  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "Classifier :  SVC  score 1.00  avec  SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "Classifier :  DecisionTreeClassifier  score 0.98  avec  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Result:\n",
    "     def __init__(self,name, score, parameters):\n",
    "         self.name = name\n",
    "         self.score = score\n",
    "         self.parameters = parameters\n",
    "     def __repr__(self):\n",
    "         return repr((self.name, self.score, self.parameters))\n",
    "\n",
    "       \n",
    "results = []\n",
    "for key,value in classifiers.items():\n",
    "    gd_sr = GridSearchCV(estimator=value,  \n",
    "                     param_grid=params[key],\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=1,\n",
    "                     iid=True)\n",
    "    gd_sr.fit(X_train, y_train)  \n",
    "    result=Result(key,gd_sr.best_score_,gd_sr.best_estimator_)\n",
    "    results.append(result)   \n",
    "    \n",
    "    \n",
    "    \n",
    "results=sorted(results, key=lambda result: result.score, reverse=True) \n",
    "\n",
    "print ('Le meilleur resultat : \\n')\n",
    "print ('Classifier : ',results[0].name, \n",
    "       ' score %0.2f' %results[0].score, \n",
    "       ' avec ',results[0].parameters,'\\n')\n",
    "\n",
    "print ('Tous les résultats : \\n')\n",
    "for result in results:\n",
    "    print ('Classifier : ',result.name, \n",
    "           ' score %0.2f' %result.score, \n",
    "           ' avec ',result.parameters,'\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il peut arriver que différentes combinaisons de pré-traitements puissent être utilisées. Par exemple il est possible d'utiliser du changement d'échelle, du PCA (projection sur un nombre différent de dimensions), de faire du remplacement de valeurs manquantes ...  \n",
    "\n",
    "L'objectif du pipeline est de pouvoir regrouper l'ensemble de ces prétraitements et de pouvoir les faire suivre par le classifier.\n",
    "Le principe consiste à d'abord mettre la chaîne de pré-traitement, d'ensuite mettre le classifier et d'utiliser directement le pipeline.\n",
    "\n",
    "** Attention ** les pipelines sont très importants lorsque l'on sauvegarde un modèle. En effet comme ils prennent en compte les pré-traitements tout est sauvegardé. Cela veut dire que dans le cas de nouvelles données à évaluer avec un modèle lors de la prédiction les données seront automatiquement transformées. (Voir partie utiliser de nouvelles données plus bas).\n",
    "\n",
    "L'exemple suivant illustre un pipeline où un standard scaling est réalisé puis un PCA et enfin un DecisionTree est appliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du pipeline \n",
      "\n",
      "\n",
      " accuracy: 0.9142857142857143 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "#transformation de Species en float pour StantardScaler\n",
    "class_label_encoder = LabelEncoder()\n",
    "df['Species']=class_label_encoder.fit_transform(df['Species'].values)\n",
    "\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "\n",
    "print ('Création du pipeline \\n')\n",
    "pipeline = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'utiliser GridSearch pour chercher les meilleures valeurs dans un pré-traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du pipeline \n",
      "\n",
      "meilleur score  0.9555555555555556 \n",
      "\n",
      "meilleurs paramètres {'pca__n_components': 2} \n",
      "\n",
      "meilleur estimateur Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'))]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "print ('Création du pipeline \\n')\n",
    "pipeline = Pipeline([('pca', PCA()),\n",
    "                    ('clf', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "grid_param = {\n",
    "    'pca__n_components': [2,3]\n",
    "}\n",
    "\n",
    "\n",
    "gd_sr = GridSearchCV(pipeline,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=1,\n",
    "                     iid=True,\n",
    "                    return_train_score=True)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "\n",
    "print ('meilleur score ',gd_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', gd_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',gd_sr.best_estimator_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou bien de faire les deux en même temps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meilleur score  0.9555555555555556 \n",
      "\n",
      "meilleurs paramètres {'pca__n_components': 2} \n",
      "\n",
      "meilleur estimateur Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "#transformation de Species en float pour StantardScaler\n",
    "class_label_encoder = LabelEncoder()\n",
    "df['Species']=class_label_encoder.fit_transform(df['Species'].values)\n",
    "\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "pipeline = Pipeline([('pca', PCA()),\n",
    "                    ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "\n",
    "grid_param = [{'pca__n_components': [2,3]},\n",
    "                {'clf': [DecisionTreeClassifier()],\n",
    "                 'clf__max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "                 'clf__criterion': ['gini', 'entropy'],\n",
    "                 'clf__min_samples_leaf': [1,2,3,4,5,6,7,8,9,10]\n",
    "                }]\n",
    "\n",
    "\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=pipeline,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1,\n",
    "                    iid=True,\n",
    "                    return_train_score=True)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)  \n",
    "print ('meilleur score ',gd_sr.best_score_,'\\n')\n",
    "print ('meilleurs paramètres', gd_sr.best_params_,'\\n')\n",
    "print ('meilleur estimateur',gd_sr.best_estimator_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder le modèle appris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois un modèle appris il est possible de le sauvegarder pour pouvoir lui appliquer d'autres données à prédire. Deux librairies existent : **pickle** et **joblib**.    \n",
    "Pickle est la librairie Python standard pour sérialiser-désérialiser des objets. standard Python tool for object (de)serialization. Joblib propose également de sérialiser-désérialiser des objets lorsque ceux-ci sont très volumineux.   \n",
    "Le choix des deux dépend des usages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparation des données\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
    "df = pd.read_csv(url, names=names)\n",
    "array = df.values\n",
    "X = array[:,0:4] \n",
    "y = array[:,4]\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pickle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour sérialiser et sauvegarder le modèle appris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'pkl_modelNB.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle sauvegardé : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé GaussianNB(priors=None, var_smoothing=1e-09) \n",
      "\n",
      "\n",
      " accuracy:\n",
      "\n",
      "0.9428571428571428 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[34  0  0]\n",
      " [ 0 33  5]\n",
      " [ 0  1 32]]\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        34\n",
      "Iris-versicolor       0.97      0.87      0.92        38\n",
      " Iris-virginica       0.86      0.97      0.91        33\n",
      "\n",
      "      micro avg       0.94      0.94      0.94       105\n",
      "      macro avg       0.95      0.95      0.94       105\n",
      "   weighted avg       0.95      0.94      0.94       105\n",
      "\n",
      "\n",
      "La prédiction du modèle pour [ 5.0,  3.6,  1.4,  0.2] est ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_loaded = pickle.load(open(filename, 'rb'))\n",
    "print ('Modèle chargé',clf_loaded,'\\n')\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "print('\\n accuracy:\\n')\n",
    "print (accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "print ('\\n',classification_report(y_test, result))\n",
    "\n",
    "result = clf_loaded.predict([[ 5.0,  3.6,  1.4,  0.2]])\n",
    "print ('\\nLa prédiction du modèle pour [ 5.0,  3.6,  1.4,  0.2] est', \n",
    "       result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**joblib**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour sérialiser et sauvegarder le modèle appris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_modelNB.sav']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'job_modelNB.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle sauvegardé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      " accuracy:\n",
      "\n",
      "0.9428571428571428 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_loaded = joblib.load(filename)\n",
    "print (clf_loaded)\n",
    "#result = clf_loaded.score(X_test, y_test)\n",
    "#print(result)\n",
    "\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "print('\\n accuracy:\\n')\n",
    "print (accuracy_score(result, y_test),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser de nouvelles données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir d'un modèle sauvegardé, il est donc possible d'appliquer la fonction predict pour connaître la prédiction du modèle.   \n",
    "\n",
    "Dans le cas de nouvelles données il faut faire attention car des pré-traitements ont sans doute été effectués avec les données initiales (changement d'échelle, normalisation, etc) et une matrice a été obtenue pour apprendre un modèle.   \n",
    "\n",
    "Il est impératif que les nouvelles données suivent le même traitement. Nous présentons par la suite un exemple d'utilisation à l'aide des données IRIS. Cette fois-ci nous utilisons iris qui est disponible directement dans scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture de la base iris et utilisation de SVM comme classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps nous ajoutons du bruit dans la base iris en mettant pour trois colonnes des valeurs supérieures à 1000. L'objectif ici est de montrer que les valeurs sont trop différentes pour obtenir de bons résultats de classification. Nous avons vu (Ingénierie des données) que SVM était très sensible à la standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(iris.data)):\n",
    "    for j in range (0,2):\n",
    "        val = iris.data[i][j]\n",
    "        value = val*1000\n",
    "        iris.data[i][j]=value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de X et de y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de comptage pour voir combien d'instances sont mal classés après la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpt_mal_classes(y_test,result):\n",
    "    nb=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] != result [i]:\n",
    "            nb=nb+1\n",
    "    return nb       \n",
    "\n",
    "def print_nb_classes (taille,nb):\n",
    "    print (\"Taille des données\",\n",
    "       taille, \n",
    "       \" mal classés\",nb)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première classification avec SVM. L'objectif ici est de montrer que SVM est très sensible à la standardisation. Il suffit de regarder l'accuracy pour s'en convaincre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données 105  mal classés 46\n",
      "\n",
      " accuracy : 0.5619047619047619 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result = clf.predict(X_test)\n",
    "nb=cpt_mal_classes(y_test,result)\n",
    "taille=len(y_test)\n",
    "print_nb_classes (len(y_test),nb)\n",
    "print('\\n accuracy :', accuracy_score(result, y_test),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite nous allons donc utiliser MinMaxScaler () pour standardiser les données.   \n",
    "\n",
    "Nous sauvegardons également le jeu de test (X_save=X_test.copy()). L'objectif est de sauvegarder le modèle pour évaluer en le rechargeant si le nombre d'instances bien classées est le même que celui qui a été prédit lors de l'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standadisation des données et sauvegarde du jeu de test avant le passage par la standardisation. La standardisation a été faite car les valeurs du jeu de données ne permettait pas de pouvoir utiliser le classifieur directement. En sauvegardant le jeu avant la standardisation nous simulons le fait que nous arrivons avec un nouveau jeu de données d'iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_save=X_test.copy()\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données 105  mal classés 5\n",
      "\n",
      " accuracy : 0.9523809523809523 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "result = clf.predict(X_test)\n",
    "nb=cpt_mal_classes(y_test,result)\n",
    "taille=len(y_test)\n",
    "print_nb_classes (len(y_test),nb)\n",
    "print('\\n accuracy :', accuracy_score(result, y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde du modèle appris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde du modèle\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSauvegarde du modèle\") \n",
    "filename = 'firstmodel.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture du modèle pour le tester. Ici nous reprenons le jeu de test qui n'a pas eu l'étape de standardisation comme nouvelles données, i.e. nous avons de nouveaux IRIS. Si le modèle est bien appris le nombre d'objets mal classés devrait être le même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle \n",
      "\n",
      "Taille des données 105  mal classés 72\n"
     ]
    }
   ],
   "source": [
    "print (\"Chargement du modèle \\n\")\n",
    "filename = 'firstmodel.pkl'\n",
    "clf_loaded = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "result=clf_loaded.predict(X_save)\n",
    "\n",
    "nb=cpt_mal_classes(y_test,result)\n",
    "taille=len(y_test)\n",
    "print_nb_classes (len(y_test),nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater qu'il y a plus d'objets mal classés. Comme nous avons fait une standardisation dans les étapes précédentes celle là n'a pas pu être faite pour les nouvelles données. La standardisation doit donc être faite pour les nouvelles données mais elle nécessite de pouvoir récupérer les anciennes valeurs pour tout standardiser.   \n",
    "\n",
    "Les pipelines sont donc utiles\n",
    "pour pouvoir tout sauvegarder (l'étape de standardisation et l'application du modèle). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données 105  mal classés 5\n",
      "\n",
      " accuracy: 0.9523809523809523 \n",
      "\n",
      "\n",
      "Sauvegarde du pipeline \n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vect', preprocessing.MinMaxScaler()),\n",
    "                ('clf', svm.SVC(gamma='scale')),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "X_save=X_test.copy()\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "result = pipeline.predict(X_test)\n",
    "\n",
    "nb=cpt_mal_classes(y_test,result)\n",
    "taille=len(y_test)\n",
    "print_nb_classes (len(y_test),nb)\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "\n",
    "print(\"\\nSauvegarde du pipeline \") \n",
    "filename = 'avecscaler.pkl'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle \n",
      "\n",
      "Taille des données 105  mal classés 5\n"
     ]
    }
   ],
   "source": [
    "print (\"Chargement du modèle \\n\")\n",
    "filename = 'avecscaler.pkl'\n",
    "clf_loaded = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "result=clf_loaded.predict(X_save)\n",
    "nb=cpt_mal_classes(y_test,result)\n",
    "taille=len(y_test)\n",
    "print_nb_classes (len(y_test),nb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
